{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports \n",
    "from keras.applications import ResNet50 # 50 layer Neural Network\n",
    "from keras.applications import imagenet_utils # Helper function that uses the Imagenet Utilities\n",
    "from keras.preprocessing import image # For dealing with images\n",
    "import numpy as np # Numpy array operations handling\n",
    "import cv2\n",
    "import argparse\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dimension of Image is 224*224 for the ConvNN\n",
    "inputShape = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiating the ResNet50 NN using the activations of imagenet. \n",
    "# NOTE: If the activations are not available, they'll be downloaded and will take time\n",
    "model = ResNet50(weights = \"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(image_path):\n",
    "    # Loading and image and making it of dimension 224*224*3 : Height, Width, Channel (RGB)\n",
    "    img = image.load_img(image_path, target_size = inputShape)\n",
    "    # Converting the image from PIL/Pillow format to Numpy Array\n",
    "    img = image.img_to_array(img)\n",
    "    # print(img.shape)\n",
    "    # Since ResNet50 needs a 4D tensor as input for the convolutional neural network to work\n",
    "    # therefore, we add one more dimension to convert it from (224,224,3) to (1,224,224,3)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    # print(img.shape)\n",
    "    # Preprocessing the images by subtracting the mean of each channel and thereby generating\n",
    "    # the feature vector for our image\n",
    "    features = imagenet_utils.preprocess_input(img)\n",
    "    # Return the feature vector\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(features):\n",
    "    # Given the features of our image, we predict the feature vector of the most close match\n",
    "    # of our image using neural network i.e, the probabilities of being a part of some class\n",
    "    predicted_features = model.predict(features)\n",
    "    # Returns the List of Top 5 predicted classes out of 1000 for our given image based on probability\n",
    "    return imagenet_utils.decode_predictions(predicted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. desktop_computer: 44.37%\n",
      "2. monitor: 39.41%\n",
      "3. screen: 11.57%\n",
      "4. projector: 1.52%\n",
      "5. television: 0.98%\n"
     ]
    }
   ],
   "source": [
    "# Generate Prediction Class for our image by passing the correct path of the image\n",
    "# img = sys.argv[1]\n",
    "img = \"/home/srvsaha/Downloads/pc.jpg\"\n",
    "# P = prediction(preprocessing(\"./05-caption-images/COCO_val2014_000000002225.jpg\"))\n",
    "P = prediction(preprocessing(img))\n",
    "# Output Top 5 predicted classes based on decreasing order of their probability\n",
    "for (i, (imagenetID, label, prob)) in enumerate(P[0]):\n",
    "\tprint(\"{}. {}: {:.2f}%\".format(i + 1, label, prob * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For GUI using OpenCV\n",
    "# load the image via OpenCV, draw the top prediction on the image,\n",
    "# and display the image to our screen\n",
    "orig = cv2.imread(img)\n",
    "(imagenetID, label, prob) = P[0][0]\n",
    "cv2.putText(orig, \"Label: {}, {:.2f}%\".format(label, prob * 100),\n",
    "\t(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "cv2.imshow(\"Classification\", orig)\n",
    "cv2.waitKey(0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
